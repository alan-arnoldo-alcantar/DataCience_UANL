{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tercera practica consiste en obtener información simple y descriptiva que de indicios sobre los patrones que tiene nuestro problema. La idea es responder preguntas simples que ayuden posteriormente a formular nuestras hipótesis para futuras prácticas.\n",
    "\n",
    "En la practica anterior se estructuro los datos de acuerdo a las distintas combinaciones de parámetros del diseño de experimentos para cada método de solución, sin embargo, para facilitarnos la tarea se trabaja con los datos crudos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_rows', 10)\n",
    "datos1=pd.read_csv('../mlp_datos.csv')\n",
    "datos2=pd.read_csv('../mlp_datos2.csv')\n",
    "datos=pd.concat([datos1,datos2])\n",
    "datos=datos.rename(columns = {'trainig_time':'training_time'})\n",
    "adam=datos.loc[datos.solver=='adam',['partition','layer_num','neurona_num','activation','alpha',\\\n",
    "                                    'learning_rate_init','train_accuracy','training_time','test_accuracy']]\n",
    "lbfgs=datos.loc[datos.solver=='lbfgs',['partition','layer_num','neurona_num','activation','alpha',\\\n",
    "                                            'train_accuracy','training_time','test_accuracy']]\n",
    "adam.to_csv('adam_crudo.csv')\n",
    "lbfgs.to_csv('lbfgs_crudo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera pregunta es comparar ambos solver comparando las medias de los rendimientos en la fase de prueba, tomando como variable el porcentaje de datos para entrenar. Para esta pregunta propondremos que el solver `adam` es mejor que  el `lbfgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in lbfgs.partition.unique():\n",
    "    print(adam.test_accuracy[adam.partition==i].mean()>lbfgs.test_accuracy[lbfgs.partition==i].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer el solver `lbfgs` es mejor que el `adam` en cada uno de los porcentajes de entrenamiento. Sin embargo, pudiera ser que bajo una combinación de los demás factores el solver `adam` sea mejor que el `lbfgs`. Para responder lo anterior veremos si el máximo del `Adam` es mejor que el de `lbfgs`, de nueva cuenta tomando como variable el porcentaje de datos para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in lbfgs.partition.unique():\n",
    "    print(adam.test_accuracy[adam.partition==i].max()>lbfgs.test_accuracy[lbfgs.partition==i].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos indica de una forma burda que el solver `lbfgs` es mejor que el `Adam`, sin embargo, es necesario realizar una prueba de hipótesis para confirmar tal sospecha. Esto nos indica de una forma burda que el solver `lbfgs` es mejor que el `Adam`, sin embargo, es necesario realizar una prueba de hipótesis para confirmar tal sospecha. Solo para realizar un análisis mas a profundidad dejaremos de lado los datos del solver `adam` y nos enfocaremos solo en los de `lbfgs`. Ahora nos enfocaremos en ver como afecta el numero de capas en el rendimiento de prueba, para ello compararemos cada nivel del factor número de capas con el anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  7, 10], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs.layer_num.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "False\n",
      "7 4\n",
      "False\n",
      "10 7\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "layers=lbfgs.layer_num.unique()[:]\n",
    "for i in range(1,len(layers)):\n",
    "    print(layers[i],layers[i-1])\n",
    "    print(lbfgs.test_accuracy[lbfgs.layer_num==layers[i]].mean()>lbfgs.test_accuracy[lbfgs.layer_num==layers[i-1]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente a medida que se aumenta el numero de capas el rendimiento promedio de prueba disminuye, pudiera ser que hay una correlación entre estas dos variables o que los niveles de los factores aun no revisados estén jugando un papel muy importante. Antes de avanzar es buena idea observar cuales son los puntos máximos y mínimos, además de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capa  1  min= 0.7417 prom= 0.9299193055555547 max= 0.9653 var= 0.0006301311741354017\n",
      "capa  4  min= 0.0274 prom= 0.381392824074076 max= 0.9629 var= 0.15545136527965406\n",
      "capa  7  min= 0.0576 prom= 0.3773751855287596 max= 0.9608 var= 0.15432714246052134\n",
      "capa  10  min= 0.0892 prom= 0.37623732590529585 max= 0.9586 var= 0.15297421632094566\n"
     ]
    }
   ],
   "source": [
    "for i in lbfgs.layer_num.unique():\n",
    "    print('capa ',i,' min=',lbfgs.test_accuracy[lbfgs.layer_num==i].min(),'prom=',\\\n",
    "          lbfgs.test_accuracy[lbfgs.layer_num==i].mean(),'max=',lbfgs.test_accuracy[lbfgs.layer_num==i].max(),\\\n",
    "          'var=',lbfgs.test_accuracy[lbfgs.layer_num==i].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior deja mas que claro el **impacto que juegan los demás factores**, porque a pesar de que con una capa se obtiene un conjunto de rendimientos de prueba que están mas “compactos” y cuyo mínimo supera por mucho a los mínimos de los otros niveles del factor numero de capas, se observa que los máximos en cada nivel son muy parecidos, incluso es difícil ver si uno es mejor que los demás. De nuevo, para seguir adelante supondremos que los mejores resultados se obtienen utilizando una cada y revisaremos como afecta el numero de neuronas, de mismo modo compararemos el nivel actual con el anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particion  10\n",
      "0.8664316666666668\n",
      "0.9046850000000001\n",
      "0.9146433333333331\n",
      "0.9190033333333332\n",
      "particion  20\n",
      "0.8886833333333334\n",
      "0.9214600000000003\n",
      "0.9298383333333331\n",
      "0.9341849999999998\n",
      "particion  30\n",
      "0.8985716666666667\n",
      "0.9284849999999998\n",
      "0.9369866666666666\n",
      "0.9410249999999993\n",
      "particion  40\n",
      "0.902971666666667\n",
      "0.9333900000000003\n",
      "0.9416150000000003\n",
      "0.9451633333333334\n",
      "particion  50\n",
      "0.9075533333333335\n",
      "0.9370133333333331\n",
      "0.944965\n",
      "0.9487233333333335\n",
      "particion  60\n",
      "0.9104550000000005\n",
      "0.9391883333333332\n",
      "0.9468000000000002\n",
      "0.9508516666666668\n",
      "particion  70\n",
      "0.9107966666666667\n",
      "0.9409283333333333\n",
      "0.9491666666666663\n",
      "0.9530449999999999\n",
      "particion  80\n",
      "0.9139416666666669\n",
      "0.9429116666666665\n",
      "0.9508983333333335\n",
      "0.9547266666666666\n",
      "particion  90\n",
      "0.9162833333333332\n",
      "0.9443166666666666\n",
      "0.9518366666666666\n",
      "0.9555550000000002\n"
     ]
    }
   ],
   "source": [
    "for j in lbfgs.partition.unique():\n",
    "    print('particion ', j)\n",
    "    for i in lbfgs.neurona_num.unique():\n",
    "        print(lbfgs.test_accuracy[(lbfgs.neurona_num==i) & (lbfgs.layer_num==1) & (lbfgs.partition==j)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí parece que los mejores resultados se obtienen utilizando el 90% de los datos con una capa de 210 neuronas. Además, que no parece importar que porcentaje tomemos para entrenar el rendimiento se mejora a medida que se aumenta el número de neuronas. El siguiente paso seria ver que efecto tiene la función de activación a elegir sobre el rendimiento de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logistic' 'tanh']\n",
      "0.95272\n",
      "0.95839\n"
     ]
    }
   ],
   "source": [
    "print(lbfgs.activation.unique())\n",
    "for j in lbfgs.activation.unique():\n",
    "    print(lbfgs.test_accuracy[(lbfgs.neurona_num==210) & (lbfgs.layer_num==1) & (lbfgs.partition==90) & (lbfgs.activation==j)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Están pruebas simples indican que utilizar la función de activación **tangente hiperbólica es mejor** es mejor que la sigmoide, pero es necesario realizar una prueba de hipótesis ya que los promedios del rendimiento están muy cercanos. Por ultimo, falta checar que efecto tiene el factor de penalización (Alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-04 1.e+00 1.e+04]\n",
      "0.9625700000000001\n",
      "0.9620299999999998\n",
      "0.9505699999999999\n"
     ]
    }
   ],
   "source": [
    "print(lbfgs.alpha.unique())\n",
    "for j in lbfgs.alpha.unique():\n",
    "    print(lbfgs.test_accuracy[(lbfgs.activation=='tanh') & (lbfgs.neurona_num==210) & (lbfgs.layer_num==1) & (lbfgs.partition==90) & (lbfgs.alpha==j)].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo esto nos lleva a las siguientes suposiciones, el solver `lbfgs` es mejor que el `Adam`, a medida que se aumenta el porcentaje de datos para entrenar es mejor, no es necesario utilizar mas de una capa, se debe tener mucho cuidado con la función de activación al igual que con el coeficiente de penalización. Todo esto es de gran ayuda para declarar las futuras hipótesis de prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
